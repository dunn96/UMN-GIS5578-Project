{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2014 = gpd.read_file(\"water2014_clip.shp\")\n",
    "\n",
    "water2014_buffer = gpd.GeoDataFrame(water2014.buffer(500))\n",
    "water2014_buffer[\"NAME\"] = water2014[\"NAME\"]\n",
    "water2014_buffer = water2014_buffer.set_geometry(water2014_buffer[0])\n",
    "water2014_buffer = water2014_buffer[[\"NAME\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2014_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2014_buffer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = int(input(\"Provide a distance for the size of the buffer in meters: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2014 = gpd.read_file(\"water2014_clip.shp\")\n",
    "water2016 = gpd.read_file(\"water2016_clip.shp\")\n",
    "water2018 = gpd.read_file(\"water2018_clip.shp\")\n",
    "water2020 = gpd.read_file(\"water2020_clip.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_lakes(buffer, water_feat):\n",
    "    lake_buffer = gpd.GeoDataFrame(water_feat.buffer(buffer))\n",
    "    lake_buffer[\"NAME\"] = water_feat[\"NAME\"]\n",
    "    lake_buffer = lake_buffer.set_geometry(lake_buffer[0])\n",
    "    lake_buffer = lake_buffer[[\"NAME\", \"geometry\"]]\n",
    "    return lake_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer2014 = buffer_lakes(buffer_size, water2014)\n",
    "buffer2016 = buffer_lakes(buffer_size, water2016)\n",
    "buffer2018 = buffer_lakes(buffer_size, water2018)\n",
    "buffer2020 = buffer_lakes(buffer_size, water2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer2014[\"NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all metro data by finding all files ending in _metro.zip\n",
    "patterns = (gpd.read_file(r'zip://jul19_metro.zip')).to_crs('EPSG:26915')\n",
    "directory = r'/home/leex6165/gisproj/'\n",
    "path = f'{directory}*_metro.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore for now. Will be used to loop through and spatial join\n",
    "# get list of all months in directory\n",
    "months = []\n",
    "for file in glob.glob(path):\n",
    "    months.append(file[-15:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Join documentation: \n",
    "# https://geopandas.org/reference/geopandas.sjoin.html\n",
    "test = gpd.sjoin(water2014_buffer, patterns, op='intersects')\n",
    "\n",
    "#check_results = test.loc[(test['NAME'] == 'Adams Hill Pond')]\n",
    "#len(check_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of points in each lake buffer.\n",
    "test_group = test.groupby('NAME', as_index=False)['index_right'].count()\n",
    "test_group = test_group.rename(columns = {'index_right': 'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing how to join counts for each month and how to create one dataset later. \n",
    "Thought: create an empy dataframe with lakes as a row and months as header column names.\n",
    "Append each count to matching lake name for each monthly dataset. \n",
    "\n",
    "Other thought- since dataframes can be created with lists. Could create multiple lists\n",
    "and turn into a dataframe. \n",
    "\n",
    "i.e. data = [[lake1, 14, 10], [lake2, 10, 1]]\n",
    "pd.DataFrame(data, columns=['lake', 'apr19', 'may19'])\n",
    "'''\n",
    "test_dict = test_group.to_dict(orient='records')\n",
    "yearly_dict = [test_dict]\n",
    "yearly_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
