{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load hydrography data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrography = gpd.read_file(\"zip://shp_water_dnr_hydrography.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrography.head()\n",
    "for col in hydrography.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hydrography.loc[hydrography[\"wb_class\"] == \"Lake or Pond\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 7 county metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro = gpd.read_file(\"zip://shp_bdry_metro_counties_and_ctus.zip\")\n",
    "metro.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_dissolve = metro.dissolve(by = \"CO_NAME\")\n",
    "metro_dissolve.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_dissolve.is_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip hydro to metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varifying the projections\n",
    "print(metro_dissolve.crs)\n",
    "print(hydrography.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for invalid polygon geometries since the clip operation did not work\n",
    "for i in hydrography.is_valid:\n",
    "    if i == False:\n",
    "        print(\"poly is false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63955752/topologicalerror-the-operation-geosintersection-r-could-not-be-performed\n",
    "hydro_valid = hydrography.buffer(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for invalid polygon geometries since the clip operation did not work\n",
    "for i in hydro_valid.is_valid:\n",
    "    if i == False:\n",
    "        print(\"poly is false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_clip = gpd.clip(hydro_valid, metro_dissolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_clip.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_clip.head()\n",
    "\n",
    "#hydro_lake = hydro_clip.loc[hydro_clip[\"wb_class\"] == \"Lake or Pond\"]\n",
    "#hydro_lake.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 2014, 2016, 2018 water files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2018 = gpd.read_file(\"zip://impaired_2018_lakes.zip\")\n",
    "water2016 = gpd.read_file(\"zip://impaired_2016_lakes.zip\")\n",
    "water2014 = gpd.read_file(\"zip://impaired_2014_lakes.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2018.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in water2018.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2018 = water2018.drop([\"CAT\", \"CAT_DESC\", \"REACH_DESC\", \"AREA_ACRES\", \"AFFECTED_U\", \"LIKE_MEET\", \"NON_POLL\", \n",
    "                \"NAT_BACK\", \"ADD_MON\", \"APPROVED\", \"NEEDS_PLN\", \"NEW_IMPAIR\", \"HUC_8\", \"HUC_8_NAME\", \"HUC_4\", \"BASIN\", \n",
    "                \"COUNTY\", \"TRIBAL_INT\", \"INDIAN_RES\", \"AMMONIA\", \"CHLORIDE\", \"FISHESBIO\", \"HG_F\", \"HG_W\", \n",
    "                \"NUTRIENTS\", \"PCB_F\", \"PFOS_F\", \"Shape_Leng\", \"Shape_Area\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in water2016.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2016.drop([\"CAT\", \"DATASET_NA\", \"REACH_DESC\", \"AREA_ACRES\", \"AFFECTED_U\", \"TMDL_NOT_R\", \"TMDL_NOT_1\", \"IMPAIR_P_1\", \"NEW_IMPAIR\", \"NEW_IMPA_1\", \n",
    "                \"TMDL_APPRO\", \"TMDL_APP_1\", \"TMDL_NEEDE\", \"TMDL_NEE_1\", \"HUC_8\", \"HUC_8_NAME\", \"HUC_4\", \n",
    "                \"BASIN\", \"COUNTY\", \"TRIBAL_INT\", \"INDIAN_RES\", \"CHLORIDE\", \"FISHESBIO\", \"HG_F\", \"HG_W\", \n",
    "                \"NUTRIENTS\", \"PCB_F\", \"PFOS_F\", \"SHAPE_Leng\", \"SHAPE_Area\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in water2014.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2014 = water2014.drop([\"LOCATION\", \"ACRES\", \"CAT\", \"AFFECTED_U\", \"NOPLN\", \"APPROVED\", \"NEEDSPLN\", \"NEW_2014\", \n",
    "                \"HUC8\", \"HUC8_NAME\", \"HUC4\", \"BASIN\", \"ALL_COUNTI\", \"WDWMO_NAME\", \"WDWMO_TYPE\", \"Chloride\", \n",
    "                \"HgF\", \"HgW\", \"Nutrients\", \"PCBF\", \"PFOS_W\", \"SHAPE_Leng\", \"Shape_Le_1\", \"Shape_Area\"], axis = 1)\n",
    "water2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2014.rename(columns = {\"WATER_NAME\" : \"NAME\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load water 2020 data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2020 = gpd.read_file(\"wq-iw1-65.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in water2020.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2020.head()\n",
    "test = water2020[[\"Water body name\", \"AUID\", \"Water body type\", \"Use Class\", \"Pollutant or stressor\", \"geometry\"]]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.loc[(test[\"Water body type\"] == \"Lake\")]\n",
    "test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join test2 to water2018\n",
    "# output 1946 rows...there are duplicates...???\n",
    "jointest = test2.merge(water2018, on = \"AUID\")\n",
    "\n",
    "jointest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = test2.groupby(\"AUID\", as_index = False)[\"Pollutant or stressor\"].apply(\";\".join)\n",
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join test3 back to test2\n",
    "\n",
    "test4 = test2.merge(test3, how = \"inner\", on = \"AUID\")\n",
    "test4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load blockgroup data and intersecting it with the water data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockgroups_df = gpd.read_file('zip://tl_2019_27_bg.zip')\n",
    "print(f'Loaded {len(blockgroups_df):,} block groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockgroups_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blockgroups_df.crs)\n",
    "print(water2018.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_proj = blockgroups_df.to_crs('EPSG:26915')\n",
    "bg_proj.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2018_intersect_bg_proj = gpd.overlay(water2018, bg_proj, how='intersection')\n",
    "water2018_intersect_bg_proj.plot()\n",
    "water2018_intersect_bg_proj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Review Comments ###\n",
    "# add columns and then remove duplicates again\n",
    "# find lakes that have been added/removed, and look at the traffic at that spot now\n",
    "# Smaller scale? Just one city\n",
    "# function for selecting data with block groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
