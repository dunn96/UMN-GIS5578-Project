{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/geopandas/geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Nicole Dunn and Maisong Francis\n",
    "\n",
    "This python script's purpose is to clean spatial data files \n",
    "that will be used in future analysis. Cleaning the data includes \n",
    "clipping all the data to the 7 county metro as the area of interest, \n",
    "removing fields that are not needed, removing invalid geometries \n",
    "from the geodataframes, and adding geometery where there is none.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Loading all shapefile datasets in as geopandas dataframes and assiging to variables\n",
    "hydrography = gpd.read_file(\"zip://shp_water_dnr_hydrography.zip\")\n",
    "water2018 = gpd.read_file(\"zip://impaired_2018_lakes.zip\")\n",
    "water2016 = gpd.read_file(\"zip://impaired_2016_lakes.zip\")\n",
    "water2014 = gpd.read_file(\"zip://impaired_2014_lakes.zip\")\n",
    "metro = gpd.read_file(\"zip://shp_bdry_metro_counties_and_ctus.zip\")\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "### CLEANING AND CLIPPING IMPAIRED WATER 2014, 2016, AND 2018\n",
    "\n",
    "## Dropping all the unnecessary columns\n",
    "water2018 = water2018.drop([\"CAT\", \"CAT_DESC\", \"REACH_DESC\", \"USE_CLASS\", \"AFFECTED_U\", \"LIKE_MEET\", \n",
    "                            \"NON_POLL\", \"NAT_BACK\", \"ADD_MON\", \"APPROVED\", \"NEEDS_PLN\", \"IMP_PARAM\", \n",
    "                            \"NEW_IMPAIR\", \"HUC_8\", \"HUC_8_NAME\", \"HUC_4\", \"BASIN\", \"TRIBAL_INT\", \n",
    "                            \"INDIAN_RES\", \"AMMONIA\", \"CHLORIDE\", \"FISHESBIO\", \"HG_F\", \"HG_W\", \"NUTRIENTS\", \n",
    "                            \"PCB_F\", \"PFOS_F\", \"Shape_Leng\", \"Shape_Area\"], axis = 1)\n",
    "\n",
    "water2016 = water2016.drop([\"CAT\", \"DATASET_NA\", \"REACH_DESC\", \"USE_CLASS\", \"AFFECTED_U\", \"TMDL_NOT_R\", \n",
    "                            \"TMDL_NOT_1\", \"IMPAIR_PAR\", \"IMPAIR_P_1\", \"NEW_IMPAIR\", \"NEW_IMPA_1\", \n",
    "                            \"TMDL_APPRO\", \"TMDL_APP_1\", \"TMDL_NEEDE\", \"TMDL_NEE_1\", \"HUC_8\", \"HUC_8_NAME\", \n",
    "                            \"HUC_4\", \"BASIN\", \"TRIBAL_INT\", \"INDIAN_RES\", \"CHLORIDE\", \"FISHESBIO\", \"HG_F\", \n",
    "                            \"HG_W\", \"NUTRIENTS\", \"PCB_F\", \"PFOS_F\", \"SHAPE_Leng\", \"SHAPE_Area\"], axis = 1)\n",
    "\n",
    "water2014 = water2014.drop([\"LOCATION\", \"CAT\", \"AFFECTED_U\", \"NOPLN\", \"APPROVED\", \"NEEDSPLN\", \"IMPAIR_PAR\", \n",
    "                            \"NEW_2014\", \"HUC8\", \"HUC8_NAME\", \"HUC4\", \"BASIN\", \"WDWMO_NAME\", \"WDWMO_TYPE\", \n",
    "                            \"Chloride\", \"HgF\", \"HgW\", \"Nutrients\", \"PCBF\", \"PFOS_W\", \"SHAPE_Leng\", \n",
    "                            \"Shape_Le_1\", \"Shape_Area\"], axis = 1)\n",
    "\n",
    "# Renaming the columns in 2014 to match the two other years\n",
    "water2014 = water2014.rename(columns = {\"WATER_NAME\" : \"NAME\", \"ALL_COUNTI\" : \"COUNTY\", \"ACRES\" : \"AREA_ACRES\"})\n",
    "\n",
    "## Preping each dataframe for clippling\n",
    "# Locate all invalid gometries and drop them from the dataset\n",
    "water2018_drop_invalid = water2018.loc[water2018['geometry'].is_valid, :]\n",
    "\n",
    "water2016_drop_invalid = water2016.loc[water2016['geometry'].is_valid, :]\n",
    "\n",
    "water2014_drop_invalid = water2014.loc[water2014['geometry'].is_valid, :]\n",
    "\n",
    "# Cleaning the metro dataset, dissolving on the county name\n",
    "metro_dissolve = metro.dissolve(by = \"CO_NAME\")\n",
    "\n",
    "# Clipping the three impaired water files to the 7 county metro\n",
    "water2018_clip = gpd.clip(water2018_drop_invalid, metro_dissolve)\n",
    "water2016_clip = gpd.clip(water2016_drop_invalid, metro_dissolve)\n",
    "\n",
    "# 2014 needed to be reprojected - then clip was performed\n",
    "water2014_proj = water2014_drop_invalid.to_crs('EPSG:26915')\n",
    "water2014_clip = gpd.clip(water2014_proj, metro_dissolve)\n",
    "\n",
    "# Writing impaired only shp\n",
    "water2018_clip.to_file(\"water2018_impaired.shp\")\n",
    "water2016_clip.to_file(\"water2016_impaired.shp\")\n",
    "water2014_clip.to_file(\"water2014_impaired.shp\")\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "### CLEANING THE 2020 IMPAIRED WATER DATA SET\n",
    "\n",
    "# Load water 2020 data csv, selecting out the columns that we want, adding a \n",
    "# geometry column, and pulling out only the lake features.\n",
    "water2020 = gpd.read_file(\"wq-iw1-65.csv\")\n",
    "water2020 = water2020[[\"Water body name\", \"AUID\", \"County\", \"Water body type\", \"geometry\"]]\n",
    "water2020_lake = water2020.loc[(water2020[\"Water body type\"] == \"Lake\")]\n",
    "\n",
    "# Dropping the \"water body type\" field since it is no longer needed\n",
    "water2020_lake = water2020_lake[[\"AUID\", \"Water body name\", \"County\", \"geometry\"]]\n",
    "\n",
    "# Renaming the columns to match the other years of impaired water data\n",
    "water2020_lake = water2020_lake.rename(columns = {\"Water body name\" : \"NAME\", \"County\" : \"COUNTY\"})\n",
    "\n",
    "# Selecting out the 7 county metro\n",
    "counties = [\"Anoka\", \"Hennepin\", \"Ramsey\", \"Washington\", \"Carver\", \"Scott\", \"Dakota\"]\n",
    "water2020_metro = water2020_lake.loc[(water2020_lake[\"COUNTY\"].isin(counties))]\n",
    "\n",
    "# Varifying all the correct counties are there\n",
    "water2020_metro[\"COUNTY\"].unique()\n",
    "\n",
    "# Drop Duplicate AUIDs\n",
    "water2020_clean = water2020_metro.drop_duplicates(subset = [\"AUID\"])\n",
    "\n",
    "# Adding a status column to the dataframe\n",
    "water2020_clean[\"status\"] = \"Impaired\"\n",
    "\n",
    "# Writing out to impaired to csv\n",
    "water2020_clean.to_csv(\"water2020_impaired.csv\")\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "### FINDING THE SMALLEST LAKE FEATURE WITHIN THE IMPAIRED WATER DATAFRAMES\n",
    "\n",
    "# Creating a list of the gpdf \n",
    "dfs = [water2014_clip, water2016_clip, water2018_clip]\n",
    "dfs_names = [\"water2014_clip\", \"water2016_clip\", \"water2018_clip\"]\n",
    "\n",
    "# New field for impairment status in all data sets\n",
    "for df in dfs:\n",
    "    df[\"status\"] = \"Impaired\"\n",
    "\n",
    "def find_min(dfs):\n",
    "    '''Finds the smallest lake within the impaired datasets\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    dfs : list\n",
    "        The dataframes of impaired water features\n",
    "    '''\n",
    "    global minimum\n",
    "    minimum = []\n",
    "    for df in dfs:\n",
    "        minimum.append(df[\"AREA_ACRES\"].min())\n",
    "    minimum = min(minimum)\n",
    "\n",
    "# Find smallest lake size of from all impaired lakes\n",
    "find_min(dfs)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "### CLEANING THE HYDROGRAPHY DATA SET\n",
    "\n",
    "# Locate all invalid gometries and drop them from the dataset\n",
    "hydro_drop_invalid = hydrography.loc[hydrography['geometry'].is_valid, :]\n",
    "\n",
    "# Clipping hydro to the 7 county metro\n",
    "hydro_clip = gpd.clip(hydro_drop_invalid, metro_dissolve)\n",
    "\n",
    "# Narrowing down the number of features in the hydro layer to only lakes and ponds\n",
    "hydro_lake = hydro_clip.loc[hydro_clip[\"wb_class\"] == \"Lake or Pond\"]\n",
    "\n",
    "# Selecting only the lakes that are at least the size of the the impaired water dataframes\n",
    "hydro_lake = hydro_lake.loc[(hydro_lake[\"acres\"] >= minimum)]\n",
    "\n",
    "# Dropping all excess fields from the dataframe\n",
    "hydro_clean = hydro_lake.drop([\"fw_id\", \"dowlknum\", \"sub_flag\", \"wb_class\", \"lake_class\", \n",
    "                               \"shore_mi\", \"center_utm\", \"center_u_1\", \"dnr_region\", \"fsh_office\", \n",
    "                               \"outside_mn\", \"delineated\", \"delineatio\", \"delineat_1\", \"delineat_2\", \n",
    "                               \"approved_b\", \"approval_d\", \"approval_n\", \"has_flag\", \"flag_type\", \n",
    "                               \"publish_da\", \"lksdb_basi\", \"has_wld_fl\", \"wld_flag_t\", \"created_us\", \n",
    "                               \"created_da\", \"last_edite\", \"last_edi_1\", \"ow_use\", \"pwi_class\", \"map_displa\", \n",
    "                               \"shape_Leng\", \"shape_Area\", \"INSIDE_X\", \"INSIDE_Y\", \"in_lakefin\"], axis = 1)\n",
    "\n",
    "# New field for impairment status to be used when data is joined with the imparied data sets\n",
    "hydro_clean[\"status\"] = \"\"\n",
    "\n",
    "# Dissolve hydrography geometry by lake name \n",
    "hydro_clean = hydro_clean.rename(columns={'pw_basin_n': 'NAME'})\n",
    "hydro_dis = (hydro_clean.dissolve(by='NAME')).reset_index()\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "### JOINING DNR CLEAN HYDRO DATAFRAME TO THE IMPAIRED WATER DATAFRAMES\n",
    "\n",
    "def complete_hydro(waterdata, waterdata_name):\n",
    "    '''Joins the cleaned hydrography dataframe to the \n",
    "    impaired water dataframes to create complete\n",
    "    dataframes of impaired/non-impaired features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    waterdata : list\n",
    "        A list of the dataframes of impaired water features\n",
    "    waterdata_name: list\n",
    "        A list of names for the impaired water files\n",
    "    '''\n",
    "    # Combine nonimpaired with impaired. Returns a pandas dataframe\n",
    "    join_hydro = hydro_dis.merge(waterdata, on ='NAME', how='left') \n",
    "    \n",
    "    # Set geometry to hydro_dis dataset for all features\n",
    "    projected = join_hydro.set_geometry(join_hydro['geometry_x'], \n",
    "                                        crs='EPSG:26915')\n",
    "    \n",
    "    # Combine duplicate features\n",
    "    projected_dis = (projected.dissolve(by='NAME')).reset_index() \n",
    "    \n",
    "    # Pulling out the fields to keep\n",
    "    projected_dis = projected_dis[['NAME', \n",
    "                                   'geometry', \n",
    "                                   'acres', \n",
    "                                   'cty_name', \n",
    "                                   'unique_id', \n",
    "                                   'status_y']]\n",
    "    \n",
    "    # Fill status of nonimpaired lakes\n",
    "    projected_dis = projected_dis.fillna(\"nonimpaired\")\n",
    "    projected_df = projected_dis.rename(columns = {'status_y': 'status'})\n",
    "\n",
    "    projected_df.to_file(f'{waterdata_name}.shp')\n",
    "\n",
    "# Nonimpaired and impaired completed dataset for each year    \n",
    "for df in dfs:\n",
    "    for name in dfs_names:\n",
    "        complete_hydro(df, name)\n",
    "    \n",
    "# Joining geometry to impaired 2020 to create the complete dataset\n",
    "complete_hydro(water2020_clean, \"water2020_clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
